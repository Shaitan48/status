Отличная идея! Подробная документация — это ключ к успешному развитию и поддержке любого проекта. Давай структурируем ее так, чтобы она отражала текущее состояние, цели рефакторинга и дальнейшие шаги.

Я предлагаю следующую структуру документации, которую мы можем наполнять и детализировать по мере продвижения. Это будет наш основной "план игры".

---

## Документация Проекта: Status Monitor (Рефакторинг v5.x - Hybrid-Agent & Pipeline)

**Версия документа:** 1.0
**Дата последнего обновления:** [сегодняшняя дата]

### 1. Введение и Цели Проекта

*   **1.1. Описание Системы "Status Monitor" (до рефакторинга):**
    *   Краткое описание исходной системы (v4.x).
    *   Основные компоненты (Online Agent, Offline Agent, Configurator, Result Loader, Сервер Flask, БД PostgreSQL).
    *   Ключевые проблемы или ограничения старой архитектуры, которые привели к необходимости рефакторинга (например, дублирование логики в агентах, сложность поддержки разных типов агентов, ограниченная гибкость заданий).
*   **1.2. Цели Рефакторинга (v5.x):**
    *   **Основная цель:** Переход на единую архитектуру с **Hybrid-Agent** и **Pipeline-заданиями**.
    *   Унификация логики агентов.
    *   Повышение гибкости и расширяемости системы мониторинга за счет pipeline-концепции.
    *   Упрощение поддержки и разработки новых типов проверок.
    *   Улучшение качества кода серверной части (логирование, обработка ошибок, комментарии, структура).
    *   Подготовка фундамента для будущих улучшений (real-time обновления, bulk-операции, улучшенный UI/UX).
*   **1.3. Ключевые Изменения в Архитектуре v5.x:**
    *   **Hybrid-Agent:** Один тип агента, способный работать в разных режимах (получение заданий из API или файла, отправка результатов в API или файл).
    *   **Pipeline-задания:** Задания определяются как последовательность (конвейер) шагов. Каждый шаг имеет свой тип (соответствует `check_methods`) и параметры. Результат одного шага может передаваться на вход следующему.
    *   **База Данных:** Таблица `node_check_assignments` теперь содержит поле `pipeline` (JSONB) вместо отдельных полей для параметров и критериев. Устаревшие поля, связанные со старой моделью заданий, удалены или их роль изменена.
    *   **Серверное API:** Адаптировано для работы с pipeline-заданиями и Hybrid-Agent.

### 2. Архитектура Системы (v5.x - Целевая)

*   **2.1. Общая Схема:**
    *   Обновленная диаграмма (например, Mermaid), показывающая взаимодействие Hybrid-Agent, Сервера Flask, БД, Nginx, и вспомогательных утилит (Configurator, Result Loader, если они остаются или их роль меняется).
    *   *Ты уже предоставлял такую диаграмму, ее нужно будет адаптировать под Hybrid-Agent.*
*   **2.2. Компоненты Системы:**
    *   **База Данных (PostgreSQL):**
        *   Основные таблицы и их назначение (с акцентом на `node_check_assignments.pipeline`).
        *   Ключевые хранимые процедуры/функции (например, `get_active_assignments_for_object`, `generate_offline_config`, `record_check_result_proc`), и как они адаптированы под pipeline.
    *   **Серверное Приложение (Flask - `status/`):**
        *   Структура приложения (`app/`, `routes/`, `repositories/`, `services/`, `models/`, `templates/`, `static/`).
        *   Назначение каждого компонента.
        *   Взаимодействие с БД.
    *   **Nginx:**
        *   Роль обратного прокси и раздачи статики.
    *   **Hybrid-Agent (PowerShell - `powershell/hybrid-agent/`):**
        *   Основной скрипт `hybrid-agent.ps1`.
        *   Режимы работы (определяются конфигурацией).
        *   Взаимодействие с API / файловой системой.
        *   Использование модуля `StatusMonitorAgentUtils`.
    *   **Модуль `StatusMonitorAgentUtils` (PowerShell - `powershell/StatusMonitorAgentUtils/`):**
        *   `Invoke-StatusMonitorCheck`: Как он теперь обрабатывает один шаг из pipeline.
        *   Скрипты `Checks/Check-*.ps1`: Их роль как исполнителей конкретных шагов pipeline.
        *   `Test-SuccessCriteria`: Как используется для проверки результатов отдельного шага.
    *   **Конфигуратор (PowerShell - `powershell/configurator/`, если остается):**
        *   Как генерирует конфигурацию с pipeline-заданиями для Hybrid-Agent в offline-режиме.
    *   **Загрузчик Результатов (PowerShell - `powershell/result_loader/`, если остается):**
        *   Как обрабатывает файлы `.zrpu` от Hybrid-Agent и отправляет результаты на новый API (возможно, `/checks/bulk`).
*   **2.3. Потоки Данных (Data Flows):**
    *   Сценарий работы Hybrid-Agent в "онлайн" режиме (получение pipeline из API, выполнение, отправка результатов).
    *   Сценарий работы Hybrid-Agent в "офлайн" режиме (получение pipeline из файла, выполнение, сохранение результатов в файл).
    *   Сценарий работы Конфигуратора и Загрузчика (если они остаются).
    *   Взаимодействие пользователя с UI и API.

### 3. Этапы Рефакторинга (Текущий Статус и План)

*   **3.1. Завершенные Этапы:**
    *   **[ЗАВЕРШЕНО]** Рефакторинг Базы Данных:
        *   Таблица `node_check_assignments` обновлена, содержит поле `pipeline JSONB`.
        *   Удалены устаревшие поля и таблицы, связанные со старой моделью заданий.
        *   SQL-скрипты схемы (`db_schema/`) и начальных данных (`db_core_data/`, `db_seed_data/`) актуализированы.
    *   **[ЗАВЕРШЕНО]** Рефакторинг серверных репозиториев и базовых файлов:
        *   Обновлены `app/app.py`, `app/db_connection.py`, `app/db_helpers.py`, `app/auth_utils.py`, `app/commands.py`, `app/errors.py`, `app/models/user.py`.
        *   Обновлены все репозитории в `app/repositories/` для поддержки новой схемы БД и добавления логирования/комментариев.
    *   **[В ПРОЦЕССЕ, частично завершено]** Рефакторинг серверных маршрутов (`app/routes/`):
        *   Файлы `__init__.py`, `agent_routes.py`, `api_key_routes.py`, `assignment_routes.py`, `auth_routes.py`, `check_routes.py`, `data_routes.py`, `event_routes.py`, `html_routes.py`, `misc_routes.py`, `node_property_routes.py`, `node_routes.py`, `node_type_routes.py`, `subdivision_routes.py` приведены к общему стилю (комментарии, логирование, обработка ошибок).
        *   **Ключевая задача:** Убедиться, что все эндпоинты, работающие с заданиями, корректно обрабатывают `pipeline` (создание, чтение, обновление).
            *   `agent_routes.py`: `GET /assignments` и `GET /objects/{id}/offline_config` должны отдавать задания с полем `pipeline`.
            *   `assignment_routes.py`: CRUD для заданий должен работать с `pipeline`.
            *   `check_routes.py`: Эндпоинты приема результатов (`/checks`, `/checks/bulk`) должны быть готовы к результатам выполнения pipeline.
*   **3.2. Текущий Этап: Доработка Сервисов и Шаблонов Flask**
    *   **Цель:** Адаптировать сервисный слой и HTML-шаблоны для полной поддержки pipeline-заданий и Hybrid-Agent.
    *   **Задачи:**
        *   **Файл `status/app/services/node_service.py`:**
            *   **[В ПРОЦЕССЕ]** Обновить `get_processed_node_status`:
                *   Текущая реализация определяет статус узла на основе PING.
                *   **Задача:** Сделать логику более гибкой. Статус узла должен определяться результатом выполнения "главного" шага pipeline (или комбинации шагов).
                *   **Предложение:** Ввести константу `PRIMARY_STATUS_CHECK_METHOD_NAME` (сейчас 'PING'). Репозиторий `node_repository.fetch_node_ping_status` (или новая функция) должен будет выбирать данные последней проверки, соответствующей этому методу (или другому признаку, если будет более сложная логика).
                *   Рассмотреть, как агрегировать статусы, если несколько шагов влияют на общее состояние узла.
        *   **Файл `status/app/templates/manage_assignments.html` (и связанный JS):**
            *   **[ТРЕБУЕТСЯ ЗНАЧИТЕЛЬНАЯ РАБОТА]** Реализовать UI для конструктора Pipeline:
                *   Панель с доступными типами шагов (из `check_methods`).
                *   Рабочая область для сборки pipeline (drag-and-drop шагов, изменение порядка).
                *   Панель свойств для выбранного шага (редактирование `description`, `parameters` (JSON), `success_criteria` (JSON)).
                *   Клиентская валидация JSON.
                *   Сохранение/загрузка структуры pipeline на/с сервера.
        *   **Другие HTML-шаблоны (`dashboard.html`, `status_detailed.html` и т.д.):**
            *   **[В ПРОЦЕССЕ]** Убедиться, что отображение информации о заданиях (если есть) и статусах узлов соответствует новой модели.
            *   `status_detailed.html`: Модальное окно заданий должно корректно отображать pipeline (например, как JSON или список шагов).
        *   **Файл `status/app/static/style.css`:**
            *   **[ТРЕБУЕТСЯ ДОРАБОТКА]** Добавить/обновить стили для нового UI конструктора pipeline.
        *   **Файл `status/nginx/nginx.conf`:**
            *   **[ПРОВЕРЕНО, вероятно без изменений]** Проверить, не требуются ли изменения в конфигурации Nginx.
*   **3.3. Следующий Этап: Адаптация PowerShell Скриптов**
    *   **Цель:** Перевести все PowerShell компоненты на работу с Hybrid-Agent и pipeline-заданиями.
    *   **Задачи:**
        *   **Модуль `StatusMonitorAgentUtils/`:**
            *   `StatusMonitorAgentUtils.psm1`:
                *   `Invoke-StatusMonitorCheck`: Должен принимать один шаг pipeline (объект с `type`, `parameters`, `success_criteria`) и вызывать соответствующий `Checks/Check-*.ps1`.
            *   `Checks/Check-*.ps1`: Каждый скрипт реализует логику одного типа шага. Принимает `parameters` и `success_criteria` для своего шага.
        *   **Скрипт `hybrid-agent/hybrid-agent.ps1`:**
            *   Реализовать получение `pipeline` (массива шагов) из API или файла.
            *   Последовательно вызывать `Invoke-StatusMonitorCheck` для каждого шага.
            *   Определить, как обрабатывать результаты шагов (агрегировать, передавать дальше, отправлять каждый результат отдельно или общий).
            *   Адаптировать логику отправки результатов (в API или файл).
        *   **Скрипты `configurator/` и `result_loader/` (если остаются):**
            *   `configurator`: Должен генерировать файлы конфигурации, где каждое задание содержит `pipeline`.
            *   `result_loader`: Должен корректно парсить файлы `.zrpu`, содержащие результаты выполнения pipeline, и отправлять их на API (вероятно, на `/checks/bulk`).
*   **3.4. Завершающий Этап: Тестирование и Документация**
    *   **Цель:** Обеспечить стабильность и документировать новую систему.
    *   **Задачи:**
        *   Проведение End-to-End тестирования всех сценариев работы Hybrid-Agent.
        *   Обновление всей пользовательской и технической документации (README файлы, описание API).
        *   Создание Swagger/OpenAPI спецификации для нового API.
        *   Написание автоматических тестов (unit, integration) для ключевых компонентов бэкенда и PowerShell.

### 4. Детализация Заданий (Pipeline)

*   **4.1. Структура Pipeline:**
    *   Pipeline представляет собой JSON-массив объектов.
    *   Каждый объект (шаг) в массиве должен содержать как минимум:
        *   `type` (string): Имя типа шага, соответствующее `method_name` из таблицы `check_methods`.
        *   `parameters` (object, optional): JSON-объект с параметрами, специфичными для данного типа шага.
    *   Опциональные поля для шага:
        *   `description` (string): Описание назначения шага.
        *   `success_criteria` (object, optional): JSON-объект с критериями успеха для результата этого шага. Проверяется на стороне агента скриптом `Check-*.ps1`.
        *   `id_ui` (string, optional, только для UI): Уникальный идентификатор шага на стороне клиента для удобства управления в конструкторе. **Не сохраняется в БД.**
    *   *Пример pipeline был приведен ранее.*
*   **4.2. Выполнение Pipeline Агентом:**
    *   Шаги выполняются последовательно.
    *   **Вопрос для проработки:** Нужно ли передавать результат выполнения предыдущего шага на вход следующему? Если да, то в каком формате? (Это усложняет, но делает pipeline мощнее). Пока что можно считать, что каждый шаг выполняется независимо, используя только свои `parameters`.
*   **4.3. Результаты Pipeline:**
    *   Агент может отправлять результат каждого шага отдельно (каждый со своим `assignment_id` и, возможно, идентификатором шага в `details`).
    *   Или агент может агрегировать результаты всех шагов и отправлять один общий результат для всего pipeline-задания.
    *   **Текущее предположение по `check_routes.py`:** API ожидает один результат на одно `assignment_id`. Если pipeline состоит из нескольких значимых проверок, результаты которых нужно хранить отдельно, возможно, каждый такой шаг должен быть отдельным заданием (`assignment`) в старом смысле, а "pipeline" на уровне БД будет просто логической группировкой или последовательностью этих заданий. Либо, если один `assignment_id` для всего pipeline, то детали каждого шага должны идти в `node_check_details` с разными `detail_type`. **Это ключевой момент, который нужно прояснить для `check_routes.py` и логики агента.**

### 5. Описание API (v5.x) - Ключевые Эндпоинты

*   **(Этот раздел нужно будет полностью переписать/дополнить на основе финальной реализации маршрутов)**
*   `GET /api/v1/assignments?object_id={id}`: Для Hybrid-Agent (online). Возвращает список заданий, каждое с полем `pipeline`.
*   `GET /api/v1/objects/{id}/offline_config`: Для Configurator. Генерирует JSON-конфиг с `pipeline`-заданиями.
*   `POST /api/v1/assignments/bulk_create`: Для UI. Создание/назначение заданий. В `assignment_data` теперь ожидается `pipeline`.
*   `PUT /api/v1/assignments/{id}`: Для UI. Обновление задания, включая его `pipeline`.
*   `POST /api/v1/checks`: Для Hybrid-Agent (online) или Result Loader. Прием результата ОДНОГО шага pipeline или всего pipeline (нужно определиться). Должен корректно обрабатывать `assignment_id` и детали.
*   `POST /api/v1/checks/bulk`: Для Result Loader. Прием массива результатов.
*   ... (остальные CRUD эндпоинты для узлов, типов, подразделений, событий, API-ключей остаются концептуально теми же, но их внутренняя логика и валидация могут быть затронуты изменениями в заданиях).

### 6. План Работ по Файлам (Приоритеты)

1.  **`status/app/services/node_service.py`**: Определить, как `pipeline` влияет на общий статус узла. Адаптировать `get_processed_node_status`.
2.  **`status/app/templates/manage_assignments.html` и связанный JS**: Реализация UI конструктора pipeline.
3.  **PowerShell: `StatusMonitorAgentUtils/` и `hybrid-agent/`**: Основная работа по реализации выполнения pipeline на стороне агента.
4.  **PowerShell: `configurator/` и `result_loader/`**: Адаптация под новый формат заданий и результатов.
5.  **Остальные `status/app/templates/`**: Косметические правки для отображения pipeline.
6.  **Документация и Тесты**: Параллельно со всеми этапами.

---

Эта структура документации должна помочь нам двигаться вперед. Мы можем детализировать каждый пункт по мере необходимости.

**Сейчас, учитывая твой предыдущий запрос, давай сфокусируемся на:**

*   **Проверке и доработке `status/app/services/node_service.py`** с учетом того, как pipeline-задания могут влиять на статус узла.
*   **Обсуждении и начале работы над `status/app/templates/manage_assignments.html`** и его JavaScript логикой для конструктора pipeline.

Какой из этих двух пунктов ты бы хотел разобрать первым? Или, возможно, у тебя есть другие приоритеты на данный момент?